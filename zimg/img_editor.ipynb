{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "1adb900e-0ed2-45b9-b436-f5df5e3f53ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from imutils import contours\n",
    "\n",
    "# # Load image, grayscale, Otsu's threshold\n",
    "# image = cv2.imread('3.png')\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# thresh = cv2.threshold(gray,0,255,cv2.THRESH_OTSU + cv2.THRESH_BINARY)[1]\n",
    "\n",
    "# # Find contours, sort from left-to-right, then crop\n",
    "# cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "# cnts, _ = contours.sort_contours(cnts, method=\"left-to-right\")\n",
    "\n",
    "# ROI_number = 0\n",
    "# for c in cnts:\n",
    "#     area = cv2.contourArea(c)\n",
    "#     if area > 10:\n",
    "#         x,y,w,h = cv2.boundingRect(c)\n",
    "#         ROI = 255 - image[y:y+h, x:x+w]\n",
    "#         cv2.imwrite('ROI_{}.png'.format(ROI_number), ROI)\n",
    "#         cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "#         ROI_number += 1\n",
    "# from keras import *     4\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    # rotation_range = 10,\n",
    "    # width_shift_range = 0.2,\n",
    "    # height_shift_range = 0.2,\n",
    "    # shear_range = 0.2,\n",
    "    horizontal_flip=False,\n",
    "    fill_mode='nearest', \n",
    "    )\n",
    "# img = tf.keras.utils.load_img(\"/home/snekha/hackathons/taml/ml/code/image/test.png\")\n",
    "# data = image.img_to_array(img)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7b27851b-7424-47fb-a20d-4a84f87f16ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# im = Image.open(\"/home/snekha/hackathons/taml/ml/code/image/test.png\").convert(\"L\") \n",
    "   \n",
    "# # getting colors \n",
    "# # multiband images (RBG) \n",
    "# im1 = Image.Image.getdata(im) \n",
    "   \n",
    "# print(str(im1).decode('utf-8')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b22ad09c-c04b-4e87-9aba-5dcf86f8eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "38e5a108-08f4-4b67-8cd6-e113c276dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from math import floor\n",
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "from flask_wtf import FlaskForm\n",
    "from flask import request\n",
    "from flask import Flask\n",
    "from wtforms import StringField, PasswordField, SubmitField, BooleanField, TextAreaField\n",
    "from wtforms.validators import DataRequired, Length, Email,EqualTo, ValidationError\n",
    "from flask import render_template, url_for, flash, redirect, request, abort\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "e2804383-f17e-41c5-a30e-276f09017574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox2(img1):\n",
    "    img = 1 - img1\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    return rmin, rmax, cmin, cmax\n",
    "def RR(img):\n",
    "    rmin, rmax, cmin, cmax = bbox2(img)\n",
    "    # print(rmin, rmax, cmin, cmax)\n",
    "    npArr = img[rmin:rmax, cmin:cmax]\n",
    "    npArr = cv2.resize(npArr, dsize=(100, 100))\n",
    "    jinga = np.ones((128,128))\n",
    "    jinga[14:114,14:114] = npArr\n",
    "    npArr = jinga.reshape(128, 128 , 1)\n",
    "    return npArr\n",
    "\n",
    "def getTamilChar(tamilCharacterCode, indx):\n",
    "    return tamilCharacterCode[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "7dcb6d2f-4f7f-4965-8517-5056c29969b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_somethings():\n",
    "\n",
    "    global tamilCharacterCode, model\n",
    "\n",
    "    with open('/home/snekha/datasets/tamil_data/unicodeTamil.csv', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(reader)\n",
    "        for i in data:\n",
    "            go = i[1].split(' ')\n",
    "            charL = \"\"\n",
    "            for gg in go:\n",
    "                charL = charL + \"\\\\u\"+str(gg)\n",
    "            tamilCharacterCode.append(charL.encode('utf-8').decode('unicode-escape'))\n",
    " \n",
    "model = load_model('/home/snekha/datasets/tamil_data/tamilALLEzhuthukalKeras_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a48978e9-2bdf-4579-8314-a8a0ef91999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tamilCharacterCode = []\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "9f8b42e6-da4d-44f0-a4c4-0d6bdda17c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from imutils import contours\n",
    "# from PIL import Image\n",
    "# from pytesseract import pytesseract\n",
    "# # Load image, grayscale, Otsu's threshold\n",
    "# image = cv2.imread('tamil_ch.png')\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# thresh = cv2.threshold(gray,0,255,cv2.THRESH_OTSU + cv2.THRESH_BINARY)[1]\n",
    "\n",
    "# # Find contours, sort from left-to-right, then crop\n",
    "# cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "# cnts, _ = contours.sort_contours(cnts, method=\"left-to-right\")\n",
    "\n",
    "# ROI_number = 0\n",
    "\n",
    "# def bbox2(img1):\n",
    "#   img = 1 - img1\n",
    "#   rows = np.any(img, axis=1)\n",
    "#   cols = np.any(img, axis=0)\n",
    "#   rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "#   cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "#   return rmin, rmax, cmin, cmax\n",
    "\n",
    "\n",
    "# for c in cnts:\n",
    "#     area = cv2.contourArea(c)\n",
    "#     if area > 10:\n",
    "#         x,y,w,h = cv2.boundingRect(c)\n",
    "#         ROI = 255 - image[y:y+h, x:x+w]\n",
    "#         cv2.imwrite('ROI_{}.png'.format(ROI_number), ROI)\n",
    "#         cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "#         ROI_number += 1\n",
    "#     #     global tamilCharacterCode, model\n",
    "#     #     rmin, rmax, cmin, cmax = bbox2(img)\n",
    "#     # # print(rmin, rmax, cmin, cmax)\n",
    "#     #     npArr = img[rmin:rmax, cmin:cmax]\n",
    "#     #     npArr = cv2.resize(npArr, dsize=(100, 100))\n",
    "#     #     jinga = np.ones((128,128))\n",
    "#     #     jinga[14:114,14:114] = npArr\n",
    "#     #     npArr = jinga.reshape(128, 128 , 1)\n",
    "#     #     print(npArr)\n",
    "#         with open(\"ROI_0.png\", \"rb\") as image:\n",
    "#               f = image.read()\n",
    "#               b = bytearray(f)\n",
    "#         # att = cv2.imread('ROI_0.png')\n",
    "#         att = b \n",
    "#         imgStr = att.decode('utf-8')\n",
    "#         imgArr = imgStr.split(',')\n",
    "#         npArr = np.asarray(att, dtype=np.uint8).reshape(400,400)\n",
    "\n",
    "\n",
    "#         npArr = RR(npArr)\n",
    "#         npArr = npArr.reshape(1, 128, 128 , 1)\n",
    "#         atc = model.predict(npArr)\n",
    "\n",
    "#         percentage = atc[0]\n",
    "\n",
    "#         valsss = atc[0].argsort()[-3:][::-1]\n",
    "\n",
    "#         responseTextSt = getTamilChar(tamilCharacterCode,valsss[0])+\",\"+ getTamilChar(tamilCharacterCode,valsss[1])+ \",\"+ getTamilChar(tamilCharacterCode,valsss[2])\n",
    "\n",
    "#         responseTextSt = responseTextSt + ',%.3f,%.3f,%.3f'%(percentage[valsss[0]] *100.0,percentage[valsss[1]] *100.0,percentage[valsss[2]]*100.0)\n",
    "\n",
    "#         print(responseTextSt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "3a54384d-bb22-4136-a9d2-7f78cbdf1b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cv2.imread('ROI_0.png')\n",
    "# with open(\"ROI_0.png\", \"rb\") as image:\n",
    "#               f = image.read()\n",
    "#               b = bytearray(f)\n",
    "# b.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "216f43d6-cd28-4e6b-8714-3722dbd904d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from PIL import Image\n",
    "# from pytesseract import pytesseract\n",
    "  \n",
    "# # Defining paths to tesseract.exe\n",
    "# # and the image we would be using\n",
    "# path_to_tesseract = r\"/home/snekha/miniconda3/envs/ml38/lib/python3.8/site-packages\"\n",
    "\n",
    "  \n",
    "# # Opening the image & storing it in an image object\n",
    "# img = Image.open('ROI_0.png')\n",
    "  \n",
    "# # Providing the tesseract executable\n",
    "# # location to pytesseract library\n",
    "# pytesseract.tesseract_cmd = path_to_tesseract\n",
    "  \n",
    "# # Passing the image object to image_to_string() function\n",
    "# # This function will extract the text from the image\n",
    "# text = pytesseract.image_to_string(img)\n",
    "  \n",
    "# # Displaying the extracted text\n",
    "# print(text[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "81b228a9-477a-465b-ad70-bef6aeeadc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "18f23047-c52b-4439-91e5-afff0e044bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox2(img1):\n",
    "  img = 1 - img1\n",
    "  rows = np.any(img, axis=1)\n",
    "  cols = np.any(img, axis=0)\n",
    "  rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "  cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "  return rmin, rmax, cmin, cmax\n",
    "def RR(img):\n",
    "    rmin, rmax, cmin, cmax = bbox2(img)\n",
    "    # print(rmin, rmax, cmin, cmax)\n",
    "    npArr = img[rmin:rmax, cmin:cmax]\n",
    "    npArr = cv2.resize(npArr, dsize=(100, 100))\n",
    "    jinga = np.ones((128,128))\n",
    "    jinga[14:114,14:114] = npArr\n",
    "    npArr = jinga.reshape(128, 128 , 1)\n",
    "    return npArr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "be365838-a79d-4b27-ac79-2c7087e4211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotIm(img_):\n",
    "    plt.imshow(img_, cmap='gray')\n",
    "    plt.show()\n",
    "def bbox(img1):\n",
    "    img = 1 - img1\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    return rmin, rmax, cmin, cmax\n",
    "def getUniformImage(img):\n",
    "    rmin, rmax, cmin, cmax = bbox(img)\n",
    "    trimmedImg = img[rmin:rmax, cmin:cmax]\n",
    "    resizedImg = cv2.resize(trimmedImg, dsize=(100, 100))\n",
    "    paddedImg = np.ones((128,128))\n",
    "    paddedImg[14:114,14:114] = resizedImg\n",
    "    paddedImg = paddedImg.reshape(128, 128 , 1)\n",
    "    return paddedImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "a7870ce4-e244-4fb8-94f5-efd9f1d6f361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = cv2 image array\n",
    "# def encodeImage(data):\n",
    "#     #resize inserted image\n",
    "#     data= cv2.resize(data, (480,270))\n",
    "#     # run a color convert:\n",
    "   \n",
    "    \n",
    "#     data= cv2.cvtColor(data, cv2.COLOR_BGR2RGB)\n",
    "#     return bytes(data) #encode Numpay to Bytes string\n",
    "\n",
    "# def decodeImage(data):\n",
    "#     #Gives us 1d array\n",
    "#     decoded = np.fromstring(data, dtype=np.uint8)\n",
    "#     #We have to convert it into (270, 480,3) in order to see as an image\n",
    "#     decoded = decoded.reshape((270, 480,3))\n",
    "#     return decoded;\n",
    "\n",
    "# # Load an color image\n",
    "# image= cv2.imread('/home/snekha/hackathons/taml/ml/code/image/lat.png',1)\n",
    "\n",
    "# img_code = encodeImage(image) #Output: b'\\xff\\xd8\\xff\\xe0\\x00\\x10...';\n",
    "# img = decodeImage(img_code)\n",
    "# img\n",
    "# # from sklearn.preprocessing import OneHotEncoder\n",
    "# # onehot_data = OneHotEncoder(sparse=False)\n",
    "# # data = onehot_data.fit_transform(img)\n",
    "# # data\n",
    "# # from keras.utils.np_utils import to_categorical  \n",
    "# # b=img = to_categorical(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a3bf604f-d3f4-4a60-a975-1e0c7b6c3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetsLoc = '/home/snekha/hackathons/taml/ml/code/image/'\n",
    "from PIL import ImageEnhance\n",
    "import PIL\n",
    "from PIL import Image \n",
    "w,h = 128,128\n",
    "i = 0\n",
    "shapeL=[]\n",
    "import cv2\n",
    "from imutils import contours\n",
    "images=[]\n",
    "labels=[]\n",
    "# from keras.utils.np_utils import to_categorical  \n",
    "# encoder = OneHotEncoder(categories='auto')\n",
    "for folders in os.listdir(datasetsLoc):\n",
    "    for files in  os.listdir(datasetsLoc):   \n",
    "        # if str(files) == 'Thumbs.db' or str(files) == 't03.tiff' or str(files) == '036t01.png':\n",
    "        #   continue      \n",
    "        # print(str(folders))\n",
    "        # indx = int(str(files)[:3])\n",
    "        # if indx < numCategory:        \n",
    "            # img = PIL.Image.open(datasetsLoc+'/'+str(files)).convert(\"L\")\n",
    "            # img= np.array(img)\n",
    "            image = Image.open(datasetsLoc+'/'+str(files))\n",
    "            filter=ImageEnhance.Color(image)\n",
    "            image=filter.enhance(0)\n",
    "            thresh = 200\n",
    "            fn = lambda x : 200 if x > thresh else 0\n",
    "            \n",
    "            image = image.convert('RGBA')\n",
    "           \n",
    "\n",
    "\n",
    "            # Transparency\n",
    "            newImage = []\n",
    "            for item in image.getdata():\n",
    "                if item[:3] == (255, 255, 255):\n",
    "                    newImage.append((255, 255, 255, 0))\n",
    "                else:\n",
    "                    newImage.append(item)\n",
    "\n",
    "            image.putdata(newImage)\n",
    "            image=image.convert('L').point(fn, mode='1')\n",
    "            img=np.asarray(image, dtype=np.uint8)\n",
    "            shapeL.append(img.shape)\n",
    "            img2 = RR(img)\n",
    "            img2 = np.asarray(img2, dtype=np.uint8)\n",
    "            # img2 = encoder.fit_transform(img2)\n",
    "            images.append(img2)\n",
    "            # labels.append(indx)\n",
    "        # if i%8000 == 0:\n",
    "        #     print(str(i)+ '  ' + str(len(labels)))\n",
    "        # i = i + 1\n",
    "filIm = open('/home/snekha/hackathons/taml/ml/code/new_img/image_ALL_128x128.obj', 'wb')\n",
    "pickle.dump(images, filIm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "7cfa3627-0eff-4d65-b596-5f5bb587596e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         ...,\n",
       "         [1],\n",
       "         [1],\n",
       "         [1]],\n",
       " \n",
       "        [[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         ...,\n",
       "         [1],\n",
       "         [1],\n",
       "         [1]],\n",
       " \n",
       "        [[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         ...,\n",
       "         [1],\n",
       "         [1],\n",
       "         [1]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         ...,\n",
       "         [1],\n",
       "         [1],\n",
       "         [1]],\n",
       " \n",
       "        [[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         ...,\n",
       "         [1],\n",
       "         [1],\n",
       "         [1]],\n",
       " \n",
       "        [[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         ...,\n",
       "         [1],\n",
       "         [1],\n",
       "         [1]]], dtype=uint8)]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, h = 128, 128\n",
    "numCategory = 156\n",
    "filIm = open('/home/snekha/hackathons/taml/ml/code/new_img/image_ALL_128x128.obj', 'rb')\n",
    "images = pickle.load(filIm)\n",
    "# filLab = open('/home/snekha/datasets/tamil_data/label_ALL_128x128.obj', 'rb')\n",
    "# labels = pickle.load(filLab)\n",
    "\n",
    "import numpy as np\n",
    "# values = [1, 0]\n",
    "# n_values = np.max(images) + 1\n",
    "# images=np.eye(n_values)[images]\n",
    "# # from keras.utils.np_utils import to_categorical  \n",
    "# # b= to_categorical(images,num_classes=len(images)+1)\n",
    "# # b\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "ccf74797-f410-4bf8-b6b4-74ebee546a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotIm(img_):\n",
    "  plt.imshow(img_, cmap='gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "cea9b10c-c085-4ae3-83f2-e51f91d1e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import re\n",
    "import csv\n",
    "import pickle\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "9e5dd6be-d438-4c0e-b2b0-d7cc2d9db7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['அ', 'ஆ', 'இ', 'ஈ', 'உ', 'ஊ', 'எ', 'ஏ', 'ஐ', 'ஒ', 'ஓ', 'ஃ', 'க', 'ங', 'ச', 'ஞ', 'ட', 'ண', 'த', 'ந', 'ப', 'ம', 'ய', 'ர', 'ல', 'வ', 'ழ', 'ள', 'ற', 'ன', 'ஸ', 'ஷ', 'ஜ', 'ஹ', 'க்ஷ', 'கி', 'ஙி', 'சி', 'ஞி', 'டி', 'ணி', 'தி', 'நி', 'பி', 'மி', 'யி', 'ரி', 'லி', 'வி', 'ழி', 'ளி', 'றி', 'னி', 'ஸி', 'ஷி', 'ஜி', 'ஹி', 'க்ஷி', 'கீ', 'ஙீ', 'சீ', 'ஞீ', 'டீ', 'ணீ', 'தீ', 'நீ', 'பீ', 'மீ', 'யீ', 'ரீ', 'லீ', 'வீ', 'ழீ', 'ளீ', 'றீ', 'னீ', 'ஸீ', 'ஷீ', 'ஜீ', 'ஹீ', 'க்ஷீ', 'கு', 'ஙு', 'சு', 'ஞு', 'டு', 'ணு', 'து', 'நு', 'பு', 'மு', 'யு', 'ரு', 'லு', 'வு', 'ழு', 'ளு', 'று', 'னு', 'கூ', 'ஙூ', 'சூ', 'ஞூ', 'டூ', 'ணூ', 'தூ', 'நூ', 'பூ', 'மூ', 'யூ', 'ரூ', 'லூ', 'வூ', 'ழூ', 'ளூ', 'றூ', 'னூ', 'ா', 'ெ', 'ே', 'ை', 'ஸ்ரீ', 'ஸு', 'ஷு', 'ஜு', 'ஹு', 'க்ஷு', 'ஸூ', 'ஷூ', 'ஜ0BC2', 'ஹூ', 'க்ஷூ', 'க்', 'ங்', 'ச்', 'ஞ்', 'ட்', 'ண்', 'த்', 'ந்', 'ப்', 'ம்', 'ய்', 'ர்', 'ல்', 'வ்', 'ழ்', 'ள்', 'ற்', 'ன்', 'ஸ்', 'ஷ்', 'ஜ்', 'ஹ்', 'க்ஷ்', 'ஔ']\n"
     ]
    }
   ],
   "source": [
    "tamilCharacterCode = []\n",
    "w,h=128,128\n",
    "with open('/home/snekha/datasets/tamil_data/unicodeTamil.csv', newline='') as f:\n",
    "  reader = csv.reader(f)\n",
    "  data = list(reader)\n",
    "  for i in data:\n",
    "    go = i[1].split(' ')\n",
    "    charL = \"\"\n",
    "    for gg in go:\n",
    "      charL = charL + \"\\\\u\"+str(gg)\n",
    "    tamilCharacterCode.append(charL.encode('utf-8').decode('unicode-escape'))\n",
    "print(tamilCharacterCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9fd4d9-1d0d-4199-a22b-112530d1409b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "1fceb1e2-311b-4ec2-846f-64aa505e5323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvMklEQVR4nO3deXhTVf748fdJ99KylNJSoFCgbFqH0sUByyAKFVGkP1REQCyC4iCrO4ijo853ZHOUUUdFEEQR8YuOIo/I8mUZEIS2UHaqBQq0QgFpgbZ0S87vj4RMC12y3SRtzut58jS5uTn3k5vk03vPPYuQUqIoiufSuToARVFcSyUBRfFwKgkoiodTSUBRPJxKAori4VQSUBQPp1kSEELcLYTIEkJkCyFmaLUdRVHsI7RoJyCE8AJ+AZKBXCANGCmlPOzwjSmKYhdvjcq9FciWUh4HEEJ8CaQANSaB0NBQGRUVpVEoiqIAZGRkXJBStrp+uVZJoC1wusrjXOCPVVcQQkwAJgC0b9+e9PR0jUJRFAVACHGypuUuqxiUUi6UUiZIKRNatbohOSmK4iRaJYE8ILLK43amZYqiuBmtkkAa0EUI0VEI4Qs8DKzWaFuKothBkzoBKWWlEGIysA7wAj6RUh7SYluKothHq4pBpJQ/AD9oVb6iKI6hWgwqiodTSUBRPJxKAori4VQSUBQPp5KAong4lQQUxcOpJKAoHk4lAUXxcCoJKIqHU0lAUTycSgKK4uFUElAUD6eSgKJ4OJUEFMXDqSSgKB5OJQFF8XCaDSqiuI6UkiNHjlBcXFzrOi1btqRTp05OjMozlZWVcfjwYSorK2tdp3379oSHhzsxqupUEmiEysrKGD9+PHv37q11nREjRvDpp586MSrPlJubyz333ENBQUGt68yePZvp06c7L6jrqCTQyGzevJmffvqJ06dPU1ZWVut6+/btY+7cuQD4+/szZswYWrRo4awwG7Wff/6Z//znPwBcuHCBS5cu1flZbNy4EYPBwOjRo11zRCCldPktPj5eKtYzGAxSr9dXuz399NMSsOrWvHlzefTo0RvKunZTrPP3v//d6s/A399fpqenaxoXkC5r+P2pI4EGbM6cOWzatKnasl9++cXqcoqKihg3bhxNmjS54bmoqCj++c9/4u/vb3OcintTSaABqaysJC8vD71eD8DOnTvZsGGDQ8rdsWNHjc917dqV7OxsAgMDAWjdurX5vtI4qCTQgJw+fZrk5GQKCwsBuHLliubbPHbsGLfffjtCCACWLVvGPffco/l2FedRScDNHTx40FzLn5+fz9mzZ+u89Odoer2eixcvmh+vX7+e33//HTBe2rr99tudFouiDZUE3Nz333/PSy+95OowzBYsWGC+P2zYMJUEGgGbk4AQIhJYBoRjrOFcKKVcIIQIAVYCUUAO8JCUsvaLpEo1ZWVlvPbaa+Tm5gJw4MABF0dUu4yMDB599FEAAgIC+Mtf/kK7du1cHFXDM3LkSIYMGULHjh1dsn17jgQqgWellHuEEMFAhhBiAzAW+D8p5WwhxAxgBvCi/aE2XhUVFebz++LiYr777jsOHz7s4qjqd+rUKT777DMAgoKCSE1NpVmzZgQHB7s4soYlPj6eUaNGuWz7NicBKeUZ4Izp/hUhxBGgLZAC9Det9imwBZUE6rR161b+/Oc/I6XEYDDw22+/uTokqxUXFzNixAj69OnDF198gbe3OtNsKBzySQkhooBewC4g3JQgAM5iPF2o6TUTgAlgrGDyNPv37yc/Px8wXuo7duyYQ8qNjo6u8bBSSsnevXvNlXqOJqUkNzeXw4cPs2HDhmpJoEmTJtx6660qMbirmloQWXMDgoAM4H7T48Lrni+orwxPbDE4fPhwqdPppE6nk0IIq1uY1XabN29eja3+Kioq5N133+2w7dR1u/a+rt26d+8uL1265Opd7jTWthicP3++U+JCixaDQggf4GtguZTyG9PifCFEhJTyjBAiAjhnzzYam127dvHNN9+wb98+DAaD3eUFBgYydepUc7v/22+/HZ3uxh7iOp2O8ePHExsby7vvvlvvZUYvLy8mTJiAv78/77//PuXl5RbHdP37ys/P55VXXsHPzw+AUaNG0bNnT4vLU7Rlz9UBASwGjkgp/1HlqdVAKjDb9Pc7uyJsBCoqKsw/jLS0NHPHHWsJIfDx8TE33AFo3rw5f/7zn+nQoUO9r3/wwQdJTExk0aJF9SYBnU7Ho48+SlBQEMuWLaOoqOiG92KpgoKCapcWb7nlFrp3727ejo+Pj1XlKY5lz5FAEjAGOCCEyDQtewnjj/8rIcR44CTwkF0RNnB6vZ7JkyeTmZkJwLlzth8YtW3bliVLltC0aVPzMm9vbyIiIuwNs1adO3dm3bp15qbKL7zwAlu3brWrzL/+9a+8++67ACQlJfHWW29VS2yKc9lzdWA7UNsnN8DWchuTs2fPkpuby+7du81JwFphYWG0adMGgMjISG699dZqSUBrAQEBxMfHmx/HxcVx4cIFsrKy6hwooy7Hjh0zV4T6+vqSmZmJEAKdTkfXrl1VZyUnU9W1Glq0aBFvvvkmpaWlNpfx6KOP8tprrwHGQ2dX/0DefPNNJk2aRN++fTl79qzd5e3cuZO+ffsCxoSzadMm/vCHP9hdrmI5lQQcqLy8nJUrV5pHkdm+fTslJSVWleHj48NDDz1Ey5YtAWNFnyt67RkMBlauXEl2djYjRowwn7f7+fnRqlUrnnjiCS5dumRev6KigpUrV1brZ2AJvV5v3kcVFRV8/vnn1VodCiFISUlpUJeRExISmDJlCv/+97/NLT/dWk2XDJx9a+iXCA0GgzQYDLKwsFB269bNpstqQggphJBBQUFy//79msWak5MjQ0NDLY4rJiZGXrlypd5yr1y5ImNiYszvw5Z9UNNNp9PJH3/8URoMBs32iRYqKyvlHXfcYfFlXWe8P9SgItrYvn07c+bMAYz/yWzJ/H/84x95+eWXAWNFX1RUlCNDdIqAgADee+89c/PnlStX8vnnn9tdrsFg4NVXX2XVqlX84x//aJRNkhcvXsyOHTuYO3cu0dHRTt++SgI2uHDhAlevXgWMXX3XrFljUzk6nY7w8HBiYmIYMmSII0OslZeXF23btsVgMFh96F5fuVV7FB4/ftx8FaGiooL8/PxrjcestmvXLs6cOUNOTg5t27YlJCTEITG7i6NHj5KTk8OsWbNcE0BNhwfOvjWk0wGDwSBHjx4tw8LCZFhYmGzWrJnNh7phYWFy7969srCw0Gnx6/V6ef78efnhhx869HTgesXFxTI/P1/m5+fLHTt2yODgYLtPC0JDQ+XEiRM12CuOZ83pAKgxBhuMX3/9lT179nDkyBGbr/d36tSJhIQEwNjQp3379jRr1syRYdZJp9MRGhqq+WXGwMBAc4WmXq/ngQceqFZJWlpaysaNGy2uODUYDFy4cIEDBw7w1VdfAcbLiwMHDiQoKMjxb8CDqCRghbVr1zJt2jS7yhg4cCAfffSRgyJqGCIiIliyZEm1ZefOnSMxMZFTp05ZVdb27dvZvn07ACEhIezevVslATupJGCB3NxcZs+eTUZGhtWv9fLy4plnnqFLly4A9OjRw9HhNUhNmzZl9uzZ7Ny509x60FrFxcXMmjWL3r17M23aNNXq0EYqCdSjqKiInJwcPvnkE3NloKX8/PwICgpi2LBh9OnTR6MIbePj40OzZs0oKSmhoqKi1vUqKyu5fPky3t7eDm2o5O/vz8iRI2nZsiWfffaZ+fy0qKjI4r4JZWVlrFy5kvz8fFJTUwkMDDR3UnI1IQRBQUEEBQVRXFxsc6WoU9RUUeDsm7tWDJaVlcnhw4fLqKgom659T5kyRWZlZcmSkhJXv5UbXL58WR49elQ+8MADdb4HX19fGR0dLV9//XVN4rhy5Yo8evSoPHr0qMzMzJTdu3e3ej8HBgbKbt26yYULF2oSo61OnTol161bJ5s2baoqBhsqKSUnT54kJyfHqtc1a9aMW265hfj4eLp27apNcHYqLS0lPz+/3oq58vJysrOzzQOgOFpQUBDdunUDjP/Z+/Tpg7+/P/v27bP4v2dJSQlZWVmkp6fTo0cPevbs6RbtCSIjIykrK8PLy8vVodRJJQEN3HLLLWzYsAFfX19Xh1KrTZs28cgjj5h7B7oDPz8/Pv74Y9LS0ujfv3+d8/fVZNGiRSxfvpzNmzeTmJioUZSNz42jTyg28/PzY8qUKTz++OP4+vrWOLiHu7j55pv5y1/+4naDe3h5edG+fXteeeUVkpOTrXqtwWCgsrLSvc+/3ZA6EnAQLy8vgoKCmDx5stueAlQVExNDTEwMOTk5Nndz1kqbNm146aWX8PX1ZcuWLYDx1MzWrstK3VQScJBnn32WYcOGERkZ6epQGo2HH36Y3r17A3DmzBkef/xxLl++7OKoGh+VBBwkOjra/IVVHKNdu3bmbsXHjx+3aBgyKSUnTpwgNDSUjh07qrYDFnDfk1ZFsUF5eTnjxo1j9OjRdg3m4knUkYCHys7OZuPGjWRlZbk6FIcrKSmhpKREVRBaSCUBD5WWlsbEiRNdHYbiBtTpgIfq27cvq1at4o477nB1KBYJCwtjyZIlTJ061dWhNDoqCXioVq1akZSUROvWrV0dikWCgoK47777VCMgDajTAQ+1bt06Jk2aZB4UVfFcKgl4qJKSEvLy8updLzg4mH79+qlhwBsxlQSUOnXo0IEVK1a4RYccRRt2JwEhhBeQDuRJKYcIIToCXwItMc5WPEZKaflsloqmCgoKmDNnDnv37rX4NarBjfWklLz33nvs3r3b6rknnM0RFYPTgCNVHs8B3pZSRgMFwHgHbENxkMuXL7N48WLWr19f77oBAQEumfikMZBSsnbtWr7++mure0M6m11JQAjRDrgXWGR6LIA7gVWmVT4F/p8921Bcw9vbm4ULF/L555+rRGADnU7H+++/z1dffeXUuSNtYe+RwDvAC8C18aBaAoVSymvdvXKBtjW9UAgxQQiRLoRIP3/+vJ1huN7x48dJS0tz66aqR48eZc+ePRb1xhNCEB0dTZcuXdy6S7Q769ixI927d3f7QUVs/nSFEEOAc1JK60ffBKSUC6WUCVLKhFatWtkahtuYN28e99xzj9Wj5zqLlJIXXniBESNGUFhY6OpwFDdiT8VgEjBUCHEP4A80BRYAzYUQ3qajgXZA/dehGgG9Xk95eblbtlffvXu3uZ9AXYOKKo4jpWTFihXs2bPHrY8OwY4kIKWcCcwEEEL0B56TUo4WQvwv8CDGKwSpwHf2h+k6Op0OnU5n8Qi47kav17Nt2zaLp7i6dujq7a2uHtvDYDCwaNEiNm/e7OpQ6qXFJ/0i8KUQ4m/AXmCxBttwCl9fX959910yMzOZPHmy29fyXu/XX39l2rRp/PrrrxatHxsby7x588yJ76abbtI4QsUdOCQJSCm3AFtM948DtzqiXFcTQpCQkICvr6/bV+5UJaUkNzeXw4cPs2nTJouTV/Pmzbnjjjsa1Ht1RwUFBZw7d87qeSpcRR3zNUJlZWWkpqaSnp7e4I5eGoOlS5fy+uuvU1RU5OpQLKKSgAOVl5fzzTffEBsby9133+3Ulna5ubls3LjRHMeJEye4cuWKRa/19fXl3nvvpXfv3qp1oAOUlpY2qCswKgk4UGlpKS+99BL9+vUjOTnZqZVrhw4dYvz48TZVYAYGBjJnzhzzfImKZ1FJwIECAgJ4/fXXiY2Nddp5dVFRES+//DL79++3KQE88cQT3HXXXQ1mXIHGaOTIkaSkpNCxY0eXbF8lAQvodDpCQ0P5/fffKS4urnU9b29vkpKSuOmmmzQ9rC4rKzMf6l+8eJFvvvmG06dPW1WGn58fwcHB9O/fnwcffFCLMBULxcfHM2LECJdtX7UHtUC3bt3Ytm0bzz33XJ3rFRUVMXz4cCZMmKDpRBnff/89iYmJJCYmMnDgQM6cOWN1GYMGDSItLY2hQ4dqEKHSkKgjAQv4+PjQvn17QkJC6lxPSkleXh5nz551eAxpaWlcvHgRgB07dlg9SSoY/+OEhoYCcNtttxEVFeXACBVrhYaGEh8f7/LPQSWBBkCv1zNz5kw2bdpkcxlCCF5//XUGDx7swMgUe8THx7NmzRqXt85UScBNnTp1in/9619UVlZiMBj45ZdfbO6X0K9fP1JSUujRo4e6BOhm3KGHpkoCGjAYDFy9epWAgACLsrzBYKC8vPrgSzk5Obz99ts3LLeGEAI/Pz969+7NM888Y3M5SuOmkoAGMjMz6devH0899RRPPPFEvetv27aNZ599ttp/+uLiYrt7/HXr1o1PPvlETZKq1EklASuEhYURFxfHsWPHuHTpUq3rFRUVkZmZyZ49e9i7dy9dunQhKCio2jrHjx83tyrbs2cPGRk2DctQIyEE3bp1Iz4+nri4OPz8/BxWttL4uP6EpAEZPnw427Zt47bbbrNo/UWLFtG/f3/2799/w3Mvv/wyffv2pW/fvsyYMcOhcfr5+fHxxx+zePFilQCUeqkjASt4eXkREBBgcWvAyspKioqK+OKLL9i5c2e15w4cOOCQXmb+/v488sgjNGvWzLzMx8eHqKgolQAUi6gkoDGDwcD777+vSdlCCIKDg3n55Zfp0KGDJttQGj+VBBqw5557jkGDBhEWFubqUJQGTCUBG7Rq1Yp27drx22+/OW3YsfDwcAICAqotS0pKYsCAAU7ZvtJ4qSRgJSEE77zzDidOnCA5ORlnDJeu0+n44IMP+NOf/lRtuZoaTHEElQRs0LRpUyIjI3nggQc4cOAAP/30k8O30bJlSwYOHGge769Lly7mdv+K4kgqCdgoJCSEDz74gFWrVmmSBKKjo1m2bBm+vr4OL1tRqlJJwE4JCQksWbKEpUuXsnXrVpvKiI2NZerUqdXa9YeGhjqsY8n69etZsWKFQ8rSyqhRo0hOTnZ1GB5JJQE7RUVFMXbsWDIzM9m3b59NZfTo0YPHHnus2jK9Xs/ly5cdESK7d+9m6dKlDilLK127diUxMbHG54KCglze004LlZWVFBYW0qRJE5e26Wh8e9ZFXnrpJSZNmmTTa69vUgxw8OBBRo8e7ZDRghvCoJdvv/02n3zyyQ3Lvby8WLRoEX379nVBVNrauXMnf/zjH5k5cybjxo1zWRwqCThIWFhYndfrS0pKSE9Pr3XEoSNHjlR7fPjwYbKysjQdocidnD9/vsYrLUIIduzYYe5NefjwYWeHppmSkhKys7MpKChwaRwqCTjJyZMnSUlJsXgYcCllg536zJGklMycOdNcX+KOcz02dHYlASFEc2AREANIYByQBawEooAc4CEppWtTnZOUlZXxwQcfcOHChRueu3DhAiUlJej1ehdE1rCpZKgte48EFgA/SikfFEL4AoHAS8D/SSlnCyFmADMwzk/YKBkMBvMh+5UrV/jggw/45ZdfXByV4+l0Orsr5/R6vdOS4LWBWuqK2dvb2y1G9rk2o7WPj49LRn6y+VMVQjQD+gFjAaSU5UC5ECIF6G9a7VOMcxQ22iSwZcsW84y/lZWVnDp1ysURaWPYsGH1jrZcn9WrV/Pmm286KKK6HT9+nEGDBtX5I585c6ZbjLb8r3/9ix9++IEPP/yQ7t27O3379qT2jsB5YIkQoieQAUwDwqWU18bAPguE1/RiIcQEYAJA+/bt7QhDe6WlpRw/frzGw9LMzEx+/vlnF0RVOyEEnTp1uqGvgT3i4uLo3bu3XWX89ttvxMTEVFt25coVTp48aVe5NSkpKWH37t11rrNnzx46depU6/N+fn507txZ86OFkydPkp+fX+ecFlqyJwl4A3HAFCnlLiHEAoyH/mZSSimEqLEmR0q5EFgIkJCQ4Na1PdnZ2dx5552UlJTc8Jw71t77+fmxZMkSevXq5bAyHdFycejQodx1113Vlq1fv54HH3zQJRV+s2fPZv78+bU+3717dzZv3tzo+2jYkwRygVwp5S7T41UYk0C+ECJCSnlGCBEBnLM3SFfYuXOneciv3377jUuXLtk16Ket4uPjrf4PfG1QkZraH7iSt7f3DTF17dqVSZMm1ZgEMjIyND3KKisrq7MdRl5eHgsXLrS6Ic/1A8jUJykpicTERNd1CZdS2nwDtgHdTPf/Cswz3WaYls0A5tZXTnx8vHQ3L774osR4xcOlt5kzZ7p6V7jMnDlzXL7/nXGbP3++U/YnkC5r+P3Ze3VgCrDcdGXgOPAYxnELvxJCjAdOAg/ZuQ2nKCoq4rnnnjPPHnTo0CHNt9m8eXPeeustWrZsWes6Xbt21TwOd3X//ffTrVu3asu2bt3K22+/7aKIGie7koCUMhNIqOEptx7pQq/Xc+7cuWqXqwoLC/nxxx8dWkkVHBxM06ZNa32+VatWDB48mIiICIdtszGJjo4mOjq62jJLG1splvPIFoN5eXkMHjy4WnNNg8FQYyMfezz55JN1Tvrh5eWlxghQXM7jksD27ds5cOAAp06doqioyGHlxsbG3jC//K233qr+y7tI06ZN6d+/f7WRoa9evcrmzZsd0imrMfGoJGAwGHjjjTdYv369w8u2dLYhxTmioqJYsWIFgYGB5mWnT58mMTGR/Px8F0bmfjwqCTjKxIkT+cMf/lBtWWPs6trYtGjRgjlz5tQ538Pq1atZu3atE6OCVatWcfLkSZ577jmXNJzzmCRQUVFBSUmJTfP76XQ6838UnU7H0KFDufvuux0doqKxoKAgUlNT61znwoULbNu2zeIyy8rK7J4zcu/evRw7dozHHntMJQEtLVu2jPnz53P69GmrX9ulSxe++OIL/P39EUKoCT4bsSeffJL777/f4vX//ve/s3z5cru2OXXqVMaNG0dUVJRd5djKY5LA77//ztGjRy1ev0OHDrRr1w4wXqq6+eab1bReHqBVq1a0atXK4vVDQkKsKr9r1643lB8XF+eSjkPXeEwSsNbjjz/Oiy8aOz8KIRrlGHeK882aNYuRI0dWW2bp3JZaUd/sWnh7e+Pj4+PqMJRGxh2/VyoJXEcIgZeXl1sMNqG4Lykler3e4lGPrn2vXDFoSH3UN/06cXFxrF+//oZDNkWp6qeffiI5OZlvv/3WovUHDRrExo0b3XLuSHUkcJ2QkBBuv/12dSSg1On3339ny5YtFq/funVrbr/9du0CsoP6piuKh1NHAoqioaZNm5KSkuK2RwGgkoCiaCosLIwFCxbQokULV4dSK3U6oCgeTiUBRfFwKgkoiodTSUBRPJxKAori4dTVAZPAwECefvpp4uLi3LJpp6JoRSUBEz8/Px5++GG6dOmikoDiUdTpgMnly5cZPnw406dPV1NhKx6l0R8JlJSUcOTIkXpHFNLr9Rw9elSNGqR4nEafBI4cOcKAAQNcNuOrorg7u04HhBBPCyEOCSEOCiFWCCH8hRAdhRC7hBDZQoiVpinKXCY8PJynnnqKpKQkV4ahKG7L5iQghGgLTAUSpJQxgBfwMDAHeFtKGQ0UAOMdEait2rVrx9/+9jcGDx5c77o6nU5VCioex97TAW8gQAhRAQQCZ4A7gVGm5z/FOFvxB3Zux2a//PIL06dP59dff61zveDgYN577z1iYmLUWAKKR7E5CUgp84QQ84FTwFVgPZABFEopK02r5QJta3q9EGICMAHQdKz1S5cusXnzZkpLS+tcz8fHh6SkJDp37qxZLIrtKisrycvL49y5c64OxSoVFRXk5ORQWVlp1SjGzmTP6UALIAXoCLQBmgAWz8ghpVwopUyQUia4685R3EdeXh4DBw7k1VdfdXUoVjl9+jQDBgzg9ddfd3UotbLndGAgcEJKeR5ACPENkAQ0F0J4m44G2gF59oepvbKyMv79738TGxvLgAEDVN2AG9m4cSP79u3j7Nmz9U4iq9PpGDRoEHFxcW4xTLzBYKCgoMChk986mj176RTQWwgRiPF0YACQDmwGHgS+BFKB7+wN0hmKi4t5/vnnSU5O5s4771RJwE0YDAbmzZtn8SSyPj4+/PWvf+XWW2/VOLLGw+bTASnlLmAVsAc4YCprIfAi8IwQIhtoCSx2QJyKB1qzZg2pqakcOHDA1aHcID4+nmXLlpGcnOzqUOxm1/GSlPJV4PqTtONAg0vDQgiaNm1KUFCQq0PxeHq9nsuXL5Oens7nn39u8esCAgJo3ry5U04D2rVrx5gxY0hLS2PDhg2ab09Lrj9pchNNmzbl22+/pXv37uoSoYsdPnyYhx56yOorAZMnT2bixIm0adNGo8gaJ5UETLy8vIiMjKR169auDsVjGQwGdu/eTXp6OseOHbN4yu+QkBDi4uKIj4+nY8eOGkfZ+KgkoLiNsrIyJk2aRGZmplU9OePi4vjhhx/c4mpAQ6T2muJSR48eZenSpUgpqaioIDc31+IEEBAQwJQpU4iPj8fb29utr+ikp6fz4osvMnLkSGJjY10dTjUqCSguU15eTlZWFnPnzkVKadVrvb29ad68OU8++SSdOnXSKELHOXjwIAcPHqRnz54qCSgKQEFBAampqWRlZVmdAABmzZrF0KFDadu2xlbpihVUElCc5uLFi5w6dcp8Py0tjbNnz1r0Wl9fX7p27Wo+709ISCAuLk6zWC3Vtm1bYmJiyM7Orrd/irtSSUBxmu+//56nnnoKACmlVT+aNm3asHbtWkJCQgDjmJDu4JlnnmHcuHHccccdHDp0yNXh2EQlAUVzhYWFfPnll2zdupWSkhKrXiuEICUlhbi4OEJCQggMDNQoStv4+PgQEBBgcaXkjz/+SFFRESNHjiQ4OFjj6CyjkoCimWvn+vn5+cyYMYNLly5ZXYZOp2PixIncddddjg7PJT777DN++OEH7rrrLpUElMZt5cqV5ia/RUVFNo3x+MADDzB27Fi3OPdvzFQSUByqvLycc+fOkZ6ezpo1a2wqw9fXl7CwMOLj4xkyZIiDI3Q8nU5HREQE586da3CDnoBKAoqDZWZmcv/991NYWGhzGTfddBOrV6+mRYsWjgtMQwEBAXz55Zfs2rWLlJQUi5s7uwuVBBSb5ebmsmPHjmrLsrKyOHv2LHq93qqyYmNj6dq1KwCdO3emdevW+Pj4OCxWLQkhCAkJISQkxK1bLdZGJQHFZmlpaYwYMcIhZaWmpjJ9+nSHlKVYRyUBk+LiYmbNmkXv3r2ZNm1ag8zoznLp0iX+9re/sW/fPpvLCA4OZtasWebr/n369HFUeIqVVBIwKSsrY+XKlVy8eJGpU6eqJFCLkpISzp49y2effUZ+fr5NZQQEBBAeHs7o0aNp166dgyNUrKVGz1Cs8sILL3Dvvfdy4cIFm8v4n//5H9auXavGbnATjf5IIDg4mL59+5KdnU1OTk6t63l7exMbG0tMTIzzgmsASkpK2LNnj7l77759+zh27JhVZQQEBNCrVy9zu/+ePXsSHR3t8FgV2zT6JNC9e3fWrl3L/PnzmTlzZq3rBQcHs3z5cjp37qyGF6vi+PHj3HfffeYhs62t9QdjJ5vVq1fTrFkzwDiKk+I+Gn0SAON/+fp+2FevXuXdd98lMTGRMWPGeHydgF6vZ8mSJWRkZFBSUkJlZWX9L7qOTqcjNTWVuLg4goKC1Mg/bkp9KialpaW89957JCcn88gjj3hkEpBSotfrzaP8LFq0iF27dllVhhACLy8vhBB4e3szduxY+vXrp1HEiiOoJKCYZWZmMn36dHMiOHz4sNVl3Hzzzbz33nt4eXmh0+lUHUsDoJKAhztz5gwFBQWAsdJv+/btVg3yeY1OpyMqKoqePXuSlJTkUYf+UkpOnDjBiRMnbBolydU855NSavTGG2+Ye/vp9XqbEgBAYGAgK1asICYmxqMSABjrk0aPHs3+/fsbXL8BsCAJCCE+AYYA56SUMaZlIcBKIArIAR6SUhYI44n0AuAeoAQYK6Xco03o2jh9+jQffvghffr0oVevXq4Ox+GKiopYtWqVeVSfffv2ceXKFZvKioqK4u67jRNR+/v7ExkZ6XaDfmht+/btZGRkcOrUKasHTHEbUso6b0A/IA44WGXZXGCG6f4MYI7p/j3AWkAAvYFd9ZUvpSQ+Pl5qbc6cORKw+Pbmm29qHpMr5OTkyNDQUKv2RW23YcOGufrtuNyUKVOs3m+hoaHyxIkTTo8VSJc1/P7qPRKQUv5HCBF13eIUoL/p/qfAFowTkaYAy0wb/FkI0VwIESGlPFPfdhTtrFmzhqVLlwLGxj+XL1+2uawXXnjBPOOvGunXetOmTWPgwIGEhYW5OhQzW0/ewqv8sM8C4ab7bYHTVdbLNS27IQkIISYAEwDat29vYxiWCwwMpHXr1ly8eJHy8nLNt+cqV65cuWEUn4yMDL7++mubyvP29qZly5bmS6Z33HGH+RTAk5WVlVFQUGBuRFWfgIAAmjVrRr9+/dxuoBS7a3CklFIIYXWVqJRyIcapzElISNC8SnXs2LGkpKQwZswYtm7dqvXmXOadd97ho48+qrbM0i9qTTp37szq1avN5/qhoaF2xddYbN26lXHjxlk8eMp9993HW2+9RcuWLbUNzAa2JoH8a4f5QogI4NqYSnlAZJX12pmWuVxQUBCBgYFuM1S1o5SXl1cbxTcjI4O8PPt3uRCCpKQkevXqRfv27fH397e7zMagrKyMrVu3smXLFqv2c2BgoNv2mLQ1CawGUoHZpr/fVVk+WQjxJfBH4JKqD9DWlStXmDBhQp2do2zh7e3N3LlzVT//6xQUFDB+/Hhyc3NdHYrDWHKJcAXGSsBQIUQu8CrGH/9XQojxwEngIdPqP2C8QpCN8RLhYxrE7LHOnz/PvHnzql2KKi0t5ffff3dI+dHR0eaxFLy8vBrEHH/OtHjxYn766Sdz4ypLtGrViueff574+HgNI7OPJVcHRtby1IAa1pXAJHuDUv6roqKCsrIywNi67+OPP7ZrEM9rvL29bzg16tKlC0899ZTq5XedyspKSktL+f777/nuu+/qf4GJv78/ERERPPHEEzRv3ly7AO3kWU27GqBPP/2UBQsWAMaEYGvDnuslJyczZ86casuaNGmiEkANvv32W1577TXzPIqW0Ol0vPvuu/zpT39ym0lGaqOSgJsxGAwcPHiwWkXfwYMHHVJ29+7dzf+REhMTueWWWxxSbmN19epVDh48SFpamlWfQdu2bYmKiqJXr15069ZNwwgdQyUBN1NSUsJjjz1m/tLZMohHTYQQzJ07l0GDBgGogVMscPLkSQYPHmz16dfo0aN54403GsyQ6SoJ1GLLli3odDrGjBlDRESEJtsoKipi6dKl1Q7xy8vLycvLs6tBk7e3N2PGjLlhDL9u3brh6+trc7mexmAwUF5ebnEibtOmDY888ggDBgxoUPtZJYFarFu3ji1bttC/f3+HJYHrv0yFhYXMnj3bIdf1rxFC4Ofnx6RJk9y6RtrdGQwGq3tURkZG8sYbbzSoBAAqCTjNyZMnmTx5crUmvRUVFXaN2luTJ598khEjRphn81Gsp9frefbZZ/n5558bbs9AK3hcEmjTpg0dOnTg9OnTNvedr09paSl5eXnVBpjIzs5m8+bNNs3OW5vw8PAbap4TEhLo37+/w7bhaS5evMi5c+f46aefSE9Pr3f90NBQc2VrZGRkgxyWzqOSwLXLNtnZ2dx5551WNfqwxp49e0hJSak2OKder3doAgDjgCDDhw+vtiwgIMCh2/A0H330EXPnzrX4Uuzzzz/PhAkTAOMoyg2lMrAqj0oCYOxD0LRpU7tqxzdu3Fhns9GsrCwuXrzo8CON4OBghgwZYm7kc8stt7h1I5SGqLS01KqrAfv372fNmjXce++9bt8eoDYelwTsJaVkwYIFrFmzxunbDg8P5/33328wU3Z7guXLl/Ptt9+yc+fOBvu5qCRQh4qKCl555RXzpJnX7N2712kxDB061Dzzb3BwME2aNHHatpXaxcXF8fTTT6PT6fD29iYyMrL+F7kplQTqYDAYWLdundO216RJkxvO6RMTExk1apTTYlAsExkZySOPPOLqMBxCJQE38vzzz5OamlptmTrnV7TmkUkgMDCQO++8kyNHjjisXb61YmNjCQ8Pr7asV69eREVFuSQexXN5ZBJo3bo1K1eu5PPPP+fRRx91SQyzZs3igQceqLasIV5jVho+j0wCYPzBJSQkMH/+fFasWEFGRoYm29HpdEycOJGOHTtWW96zZ0/1o2+AgoODmT59eqNqku2xSQCgR48e9OjRgyNHjnDo0CFNtuHj48OoUaO47bbbNClfcSxvb+86x1Ns2bIlEyZMcNvxAm0hpBvMnZaQkCAtaaKplZMnTzpsiK7rCSHo0qULQUFBmpSvONaZM2c4c6b2YTF9fHzo3r17g2wZKITIkFImXL/co48ErunQoQMdOnRwdRiKG4iIiNCs67i7UiNLKIqHU0lAUTycSgKK4uFUElAUD6eSgKJ4OJUEFMXD1ZsEhBCfCCHOCSEOVlk2TwhxVAixXwjxbyFE8yrPzRRCZAshsoQQgzSKW1EUB7HkSGApcP2E9BuAGCnlH4BfgJkAQoibgIeBm02v+ZcQQk1poyhurN4kIKX8D3DxumXrpZTXBtD7GeMU5AApwJdSyjIp5QmME5Pe6sB4FUVxMEfUCYwD1prutwVOV3ku17TsBkKICUKIdCFE+vnz5x0QhqIotrArCQghZgGVwHJrXyulXCilTJBSJrRq1cqeMBRFsYPNfQeEEGOBIcAA+d9eSHlA1cHW2pmWKYripmw6EhBC3A28AAyVUladomU18LAQwk8I0RHoAuy2P0xFUbRS75GAEGIF0B8IFULkAq9ivBrgB2wwDYzxs5Tyz1LKQ0KIr4DDGE8TJkkpHTOtrqIomlDjCSiKh6htPAHVYlBRPJxKAori4VQSUBQPp5KAong4lQQUxcOpJKAoHk4lAUXxcG7RTkAIcR4oBi64OhYgFBVHVSqO6hpyHB2klDd01HGLJAAghEivqSGDikPFoeLQNg51OqAoHk4lAUXxcO6UBBa6OgATFUd1Ko7qGl0cblMnoCiKa7jTkYCiKC6gkoCieDi3SAJCiLtN8xRkCyFmOGmbkUKIzUKIw0KIQ0KIaablIUKIDUKIX01/WzgpHi8hxF4hxBrT445CiF2mfbJSCOHrhBiaCyFWmeaUOCKE6OOK/SGEeNr0mRwUQqwQQvg7a3/UMs9GjftAGP3TFNN+IUScxnFoM9+HlNKlN8ALOAZ0AnyBfcBNTthuBBBnuh+Mcf6Em4C5wAzT8hnAHCfth2eAL4A1psdfAQ+b7n8ITHRCDJ8Cj5vu+wLNnb0/MI5OfQIIqLIfxjprfwD9gDjgYJVlNe4D4B6MI20LoDewS+M47gK8TffnVInjJtPvxg/oaPo9eVm8La2/WBa82T7AuiqPZwIzXRDHd0AykAVEmJZFAFlO2HY74P+AO4E1pi/VhSofeLV9pFEMzUw/PnHdcqfuD/47bH0IxuHv1gCDnLk/gKjrfnw17gPgI2BkTetpEcd1zw0DlpvuV/vNAOuAPpZuxx1OByyeq0ArQogooBewCwiXUp4xPXUWCHdCCO9gHLjVYHrcEiiU/53gxRn7pCNwHlhiOi1ZJIRogpP3h5QyD5gPnALOAJeADJy/P6qqbR+48rtr03wfNXGHJOBSQogg4GtgupTyctXnpDGtanoNVQgxBDgnpczQcjsW8MZ4+PmBlLIXxr4c1epnnLQ/WmCcyaoj0AZowo3T4LmMM/ZBfeyZ76Mm7pAEXDZXgRDCB2MCWC6l/Ma0OF8IEWF6PgI4p3EYScBQIUQO8CXGU4IFQHMhxLXRoJ2xT3KBXCnlLtPjVRiTgrP3x0DghJTyvJSyAvgG4z5y9v6oqrZ94PTvbpX5PkabEpLdcbhDEkgDuphqf30xTmi6WuuNCuNY6YuBI1LKf1R5ajWQarqfirGuQDNSyplSynZSyiiM732TlHI0sBl40IlxnAVOCyG6mRYNwDh0vFP3B8bTgN5CiEDTZ3QtDqfuj+vUtg9WA4+arhL0Bi5VOW1wOM3m+9CykseKCpB7MNbOHwNmOWmbfTEe1u0HMk23ezCej/8f8CuwEQhx4n7oz3+vDnQyfZDZwP8Cfk7YfiyQbton3wItXLE/gNeAo8BB4DOMtd5O2R/ACox1ERUYj47G17YPMFbgvm/63h4AEjSOIxvjuf+17+uHVdafZYojCxhszbZUs2FF8XDucDqgKIoLqSSgKB5OJQFF8XAqCSiKh1NJQFE8nEoCiuLhVBJQFA/3/wGoKtUH1VrgTwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "npArr=np.array(images)\n",
    "\n",
    "# ridx = np.random.randint(images.shape[1])\n",
    "# print(tamilCharacterCode[np.argmax(y_train[ridx])])\n",
    "plotIm(npArr.reshape(w,h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "abeafa0a-12bc-4503-ac3b-3b6d4f213f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/home/snekha/datasets/tamil_data/tamilALLEzhuthukalKeras_Model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "01fe22db-c277-4463-8afb-7035c3fe6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getTamilChar(tamilCharacterCode, indx):\n",
    "#     return tamilCharacterCode[indx]\n",
    "# npArr = images[0].reshape(1, 128, 128 , 1)\n",
    "# atc = model.predict(npArr)\n",
    "# percentage = atc[0]\n",
    "# percentage\n",
    "# valsss = atc[0].argsort()[-3:][::-1]\n",
    "    \n",
    "# responseTextSt = getTamilChar(tamilCharacterCode,valsss[0])+\",\"+ getTamilChar(tamilCharacterCode,valsss[1])+ \",\"+ getTamilChar(tamilCharacterCode,valsss[2])\n",
    "    \n",
    "# responseTextSt = responseTextSt + ',%.3f,%.3f,%.3f'%(percentage[valsss[0]] *100.0,percentage[valsss[1]] *100.0,percentage[valsss[2]]*100.0)\n",
    "# responseTextSt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "cc2b521c-dd74-4363-b266-3ad7a2ef5073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTamilChar(tamilCharacterCode, indx):\n",
    "    return tamilCharacterCode[indx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "698d2ad3-16eb-4e88-a287-111f473027fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'அ,து,னு,79.820,19.068,0.508'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npArr=images[0]\n",
    "# npArr = np.asarray(images, dtype=np.uint8)\n",
    "npArr = npArr.reshape(1, 128, 128 , 1)\n",
    "# npArr=images\n",
    "atc = model.predict(npArr)\n",
    "    \n",
    "percentage = atc[0]\n",
    "valsss = atc[0].argsort()[-3:][::-1]\n",
    "responseTextSt = getTamilChar(tamilCharacterCode,valsss[0])+\",\"+ getTamilChar(tamilCharacterCode,valsss[1])+ \",\"+ getTamilChar(tamilCharacterCode,valsss[2])\n",
    "responseTextSt = responseTextSt + ',%.3f,%.3f,%.3f'%(percentage[valsss[0]] *100.0,percentage[valsss[1]] *100.0,percentage[valsss[2]]*100.0)\n",
    "responseTextSt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "893422b1-321e-4df1-adaa-caceceda6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=getTamilChar(tamilCharacterCode,valsss[0])\n",
    "file1 = open(\"tamil_pdf.txt\", \"a\")  # append mode\n",
    "file1.write(a)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0e207ca0-dba3-4800-bbf7-0121fcc87579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load image, grayscale, Otsu's threshold\n",
    "# image = cv2.imread('t.png')\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# thresh = cv2.threshold(gray,0,255,cv2.THRESH_OTSU + cv2.THRESH_BINARY)[1]\n",
    "\n",
    "# # Find contours, sort from left-to-right, then crop\n",
    "# cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "# cnts, _ = contours.sort_contours(cnts, method=\"left-to-right\")\n",
    "\n",
    "# ROI_number = 0\n",
    "# for c in cnts:\n",
    "#     area = cv2.contourArea(c)\n",
    "#     if area > 1:\n",
    "#         x,y,w,h = cv2.boundingRect(c)\n",
    "#         ROI = 255 - image[y:y+h, x:x+w]\n",
    "#         cv2.imwrite('/home/snekha/hackathons/taml/ml/code/image/ROI_{}.png'.format(ROI_number), ROI)\n",
    "#         cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "#         ROI_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3a3726b9-7920-417a-8186-5b0d64a9aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from imutils import contours\n",
    "\n",
    "# # Load image, grayscale, Otsu's threshold\n",
    "# image = cv2.imread('.png')\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# thresh = cv2.threshold(gray,0,255,cv2.THRESH_OTSU + cv2.THRESH_BINARY)[1]\n",
    "\n",
    "# # Find contours, sort from left-to-right, then crop\n",
    "# cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "# cnts, _ = contours.sort_contours(cnts, method=\"left-to-right\")\n",
    "\n",
    "# ROI_number = 0\n",
    "# for c in cnts:\n",
    "#     area = cv2.contourArea(c)\n",
    "#     if area > 10:\n",
    "#         x,y,w,h = cv2.boundingRect(c)\n",
    "#         ROI = 255 - image[y:y+h, x:x+w]\n",
    "#         cv2.imwrite('/home/snekha/hackathons/taml/ml/code/image/ROI_{}.png'.format(ROI_number), ROI)\n",
    "#         cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "#         ROI_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "44a72de7-3ead-4708-a680-4dad4a9e5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global tamilCharacterCode, model\n",
    "# att=bytes(images)\n",
    "# print(type(att))\n",
    "# # imgStr = att.decode('utf-8')\n",
    "# # imgArr = att.split(',')\n",
    "# npArr = np.asarray(images, dtype=np.uint8).reshape(400,400)\n",
    "    \n",
    "        \n",
    "# npArr = RR(npArr)\n",
    "# npArr = npArr.reshape(1, 128, 128 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f03c6d99-91cc-4c5d-b5b0-133ff1e3b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from math import floor\n",
    "# import io\n",
    "# import requests\n",
    "# from PIL import Image\n",
    "# from flask_wtf import FlaskForm\n",
    "# from flask import request\n",
    "# from flask import Flask\n",
    "# from wtforms import StringField, PasswordField, SubmitField, BooleanField, TextAreaField\n",
    "# from wtforms.validators import DataRequired, Length, Email,EqualTo, ValidationError\n",
    "# from flask import render_template, url_for, flash, redirect, request, abort\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import csv\n",
    "# from matplotlib import pyplot as plt\n",
    "# from tensorflow.keras.models import load_model\n",
    "# import pickle\n",
    "\n",
    "\n",
    "\n",
    "# tamilCharacterCode = []\n",
    "# model = None\n",
    "\n",
    "\n",
    "# def bbox2(img1):\n",
    "#   img = 1 - img1\n",
    "#   rows = np.any(img, axis=1)\n",
    "#   cols = np.any(img, axis=0)\n",
    "#   rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "#   cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "#   return rmin, rmax, cmin, cmax\n",
    "# def RR(img):\n",
    "#     rmin, rmax, cmin, cmax = bbox2(img)\n",
    "#     # print(rmin, rmax, cmin, cmax)\n",
    "#     npArr = img[rmin:rmax, cmin:cmax]\n",
    "#     npArr = cv2.resize(npArr, dsize=(100, 100))\n",
    "#     jinga = np.ones((128,128))\n",
    "#     jinga[14:114,14:114] = npArr\n",
    "#     npArr = jinga.reshape(128, 128 , 1)\n",
    "#     return npArr\n",
    "\n",
    "# def getTamilChar(tamilCharacterCode, indx):\n",
    "#     return tamilCharacterCode[indx]\n",
    "\n",
    "    \n",
    "\n",
    "# def get_post_javascript_data():\n",
    "#     global tamilCharacterCode, model\n",
    "#     att = images\n",
    "#     print(type(att))\n",
    "#     imgStr = att.decode('utf-8')\n",
    "#     imgArr = imgStr.split(',')\n",
    "#     npArr = np.asarray(imgArr, dtype=np.uint8).reshape(400,400)\n",
    "    \n",
    "        \n",
    "#     npArr = RR(npArr)\n",
    "#     npArr = npArr.reshape(1, 128, 128 , 1)\n",
    "#     atc = model.predict(npArr)\n",
    "    \n",
    "#     percentage = atc[0]\n",
    "\n",
    "#     valsss = atc[0].argsort()[-3:][::-1]\n",
    "    \n",
    "#     responseTextSt = getTamilChar(tamilCharacterCode,valsss[0])+\",\"+ getTamilChar(tamilCharacterCode,valsss[1])+ \",\"+ getTamilChar(tamilCharacterCode,valsss[2])\n",
    "    \n",
    "#     responseTextSt = responseTextSt + ',%.3f,%.3f,%.3f'%(percentage[valsss[0]] *100.0,percentage[valsss[1]] *100.0,percentage[valsss[2]]*100.0)\n",
    "    \n",
    "#     return responseTextSt\n",
    "\n",
    "\n",
    "# def init_somethings():\n",
    "\n",
    "#     global tamilCharacterCode, model\n",
    "\n",
    "#     with open('/home/snekha/datasets/tamil_data/unicodeTamil.csv', newline='') as f:\n",
    "#         reader = csv.reader(f)\n",
    "#         data = list(reader)\n",
    "#         for i in data:\n",
    "#             go = i[1].split(' ')\n",
    "#             charL = \"\"\n",
    "#             for gg in go:\n",
    "#                 charL = charL + \"\\\\u\"+str(gg)\n",
    "#             tamilCharacterCode.append(charL.encode('utf-8').decode('unicode-escape'))\n",
    "    \n",
    "    \n",
    "#     model = load_model('/home/snekha/datasets/tamil_data/tamilALLEzhuthukalKeras_Model.h5')\n",
    "#     print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e3b2dd8a-2590-4a04-932d-3298342e08ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_post_javascript_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9fd7c8c9-a20d-45b9-a106-7bde316b4096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def imageDataToGrayscale(imgData):\n",
    "            \n",
    "#                 grayscaleImg = []\n",
    "#                 y=x=0\n",
    "#                 while(y < imgData.height):\n",
    "            \n",
    "#                     grayscaleImg[y]=[]\n",
    "#                     y=y+1\n",
    "#                     while(x < imgData.width):\n",
    "                    \n",
    "#                         offset = y * 4 * imgData.width + 4 * x\n",
    "#                         alpha = imgData.data[offset+3]\n",
    "#                         # weird: when painting with stroke, alpha == 0 means white;\n",
    "#                         # alpha > 0 is a grayscale value; in that case I simply take the R value\n",
    "#                         if alpha == 0:\n",
    "                        \n",
    "#                             imgData.data[offset] = 255\n",
    "#                             imgData.data[offset+1] = 255\n",
    "#                             imgData.data[offset+2] = 255\n",
    "                        \n",
    "#                         imgData.data[offset+3] = 255\n",
    "#                         # simply take red channel value. Not correct, but works for\n",
    "#                         # black or white images.\n",
    "#                         grayscaleImg[y][x] = imgData.data[y*4*imgData.width + x*4 + 0] / 255\n",
    "#                         x=x+1\n",
    "                \n",
    "#                 return grayscaleImg\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8fc95915-5302-4167-911a-eb9f48f026bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imageDataToGrayscale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "685da2de-5d36-440e-8b8e-03c53f8582f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bbox2(img1):\n",
    "#   img = 1 - img1\n",
    "#   rows = np.any(img, axis=1)\n",
    "#   cols = np.any(img, axis=0)\n",
    "#   rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "#   cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "#   return rmin, rmax, cmin, cmax\n",
    "# def RR(img):\n",
    "#     rmin, rmax, cmin, cmax = bbox2(img)\n",
    "#     # print(rmin, rmax, cmin, cmax)\n",
    "#     npArr = img[rmin:rmax, cmin:cmax]\n",
    "#     npArr = cv2.resize(npArr, dsize=(100, 100))\n",
    "#     jinga = np.ones((128,128))\n",
    "#     jinga[14:114,14:114] = npArr\n",
    "#     npArr = jinga.reshape(128, 128 , 1)\n",
    "#     return npArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "daa58b13-6cc0-4824-9783-7313fc44d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # npArr = np.asarray(npArr, dtype=np.uint8).reshape(400,400)\n",
    "    \n",
    "        \n",
    "# npArr = RR(npArr)\n",
    "# npArr = npArr.reshape(1, 128, 128 , 1)\n",
    "# atc = model.predict(npArr)\n",
    "    \n",
    "# percentage = atc[0]\n",
    "\n",
    "# valsss = atc[0].argsort()[-3:][::-1]\n",
    "    \n",
    "# responseTextSt = getTamilChar(tamilCharacterCode,valsss[0])+\",\"+ getTamilChar(tamilCharacterCode,valsss[1])+ \",\"+ getTamilChar(tamilCharacterCode,valsss[2])\n",
    "    \n",
    "# responseTextSt = responseTextSt + ',%.3f,%.3f,%.3f'%(percentage[valsss[0]] *100.0,percentage[valsss[1]] *100.0,percentage[valsss[2]]*100.0)\n",
    "    \n",
    "# return responseTextSt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26765fe7-3f8e-49b3-b7ac-b7cebc1e42f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ced171-530e-4b05-9535-ffcb02a54915",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a9188-14c2-4b31-a94f-bd94b8fd63c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
